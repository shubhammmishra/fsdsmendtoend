{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-07 10:28:01.239649\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE=f\"{datetime.now().strftime('%m_%d_%Y_%H_%M_%S')}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DEELL\\\\Desktop\\\\fsdsmendtoend\\\\notebook'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DEELL\\\\Desktop\\\\fsdsmendtoend\\\\notebook\\\\logs'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(),\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DimondPricePridiction.logger import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(' i have just tested the things')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DEELL\\\\Desktop\\\\fsdsmendtoend\\\\notebook\\\\data\\\\gemstone.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(),\"data\\\\gemstone.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.55</td>\n",
       "      <td>13619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.03</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.06</td>\n",
       "      <td>8.12</td>\n",
       "      <td>5.05</td>\n",
       "      <td>13387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.71</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.70</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.61</td>\n",
       "      <td>4.77</td>\n",
       "      <td>14453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193568</th>\n",
       "      <td>193568</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>61.1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193569</th>\n",
       "      <td>193569</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>60.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.77</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193570</th>\n",
       "      <td>193570</td>\n",
       "      <td>0.73</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193571</th>\n",
       "      <td>193571</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.81</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193572</th>\n",
       "      <td>193572</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>60.8</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193573 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  carat        cut color clarity  depth  table     x     y  \\\n",
       "0            0   1.52    Premium     F     VS2   62.2   58.0  7.27  7.33   \n",
       "1            1   2.03  Very Good     J     SI2   62.0   58.0  8.06  8.12   \n",
       "2            2   0.70      Ideal     G     VS1   61.2   57.0  5.69  5.73   \n",
       "3            3   0.32      Ideal     G     VS1   61.6   56.0  4.38  4.41   \n",
       "4            4   1.70    Premium     G     VS2   62.6   59.0  7.65  7.61   \n",
       "...        ...    ...        ...   ...     ...    ...    ...   ...   ...   \n",
       "193568  193568   0.31      Ideal     D    VVS2   61.1   56.0  4.35  4.39   \n",
       "193569  193569   0.70    Premium     G    VVS2   60.3   58.0  5.75  5.77   \n",
       "193570  193570   0.73  Very Good     F     SI1   63.1   57.0  5.72  5.75   \n",
       "193571  193571   0.34  Very Good     D     SI1   62.9   55.0  4.45  4.49   \n",
       "193572  193572   0.71       Good     E     SI2   60.8   64.0  5.73  5.71   \n",
       "\n",
       "           z  price  \n",
       "0       4.55  13619  \n",
       "1       5.05  13387  \n",
       "2       3.50   2772  \n",
       "3       2.71    666  \n",
       "4       4.77  14453  \n",
       "...      ...    ...  \n",
       "193568  2.67   1130  \n",
       "193569  3.47   2874  \n",
       "193570  3.62   3036  \n",
       "193571  2.81    681  \n",
       "193572  3.48   2258  \n",
       "\n",
       "[193573 rows x 11 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "data= Path(os.path.join(os.getcwd(),\"data\\gemstone.csv\"))\n",
    "#data=  Path(\"notebook\\\\data\",\"gemstone.csv\")\n",
    "#os.path.join(\"notebook\\\\data\",\"gemstone.csv\")\n",
    "data = pd.read_csv(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.DimondPricePridiction.logger import logging\n",
    "from src.DimondPricePridiction.exception import customexception\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "class DataIngestionConfig:\n",
    "    raw_data_path:str= os.path.join(\"artifacts\",\"raw.csv\")\n",
    "    train_data_path:str= os.path.join(\"artifacts\",\"train.csv\")\n",
    "    test_data_path:str= os.path.join(\"artifacts\",\"test.csv\") \n",
    "\n",
    "\n",
    "\n",
    "class DataIngestion:\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ingestion_config=DataIngestionConfig()\n",
    "\n",
    "    def initiate_data_ingestion(self):\n",
    "        logging.info(\"data ingestion started\")\n",
    "\n",
    "        try:\n",
    "            data= str(Path(os.path.join(os.getcwd(),\"data\\gemstone.csv\")))\n",
    "            #data= pd.read_csv(Path(os.path.join(\"notebook/data\",\"gemstone.csv\")))\n",
    "            #data= pd.read_csv(os.path.join(os.getcwd(),\"data\\\\gemstone.csv\"))\n",
    "            logging.info(\" i have read dataset as a df\")\n",
    "            \n",
    "            os.makedirs(os.path.join(self.ingestion_config.raw_data_path),exist_ok= True)\n",
    "            data.to_csv(self.ingestion_config.raw_data_path, index=False)\n",
    "            logging.info(\" i have saved the raw dataset in artifact folder\")\n",
    "\n",
    "\n",
    "            logging.info(\" i have performed train test split\")\n",
    "            \n",
    "            train_data, test_data= train_test_split(data,test_size=0.25)\n",
    "            logging.info(\" train test split completed\")\n",
    "\n",
    "            train_data.to_csv(self.ingestion_config.train_data_path, index=False)\n",
    "            test_data.to_csv(self.ingestion_config.test_data_path, index=False)\n",
    "            \n",
    "            logging.info(\"data ingestion part completed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.info(\"exception during data ingestion steps\")\n",
    "            raise customexception(e,sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.DimondPricePridiction.exception import customexception\n",
    "from src.DimondPricePridiction.logger import logging\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder,StandardScaler\n",
    "from src.DimondPricePridiction.utils.utils import save_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    preprocessor_obj_file_path=os.path.join('artifacts','preprocessor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_transformation_config= DataTransformationConfig()\n",
    "\n",
    "    def get_data_transformation(self):\n",
    "        try:\n",
    "            \n",
    "            logging.info(\"Data transformation initiated\")\n",
    "\n",
    "            # Define which column should be ordinal encoded and which should be scaled\n",
    "            categorical_cols= ['cut','clarity','color']\n",
    "            numerical_cols= ['carat','depth','table','x','y','z']\n",
    "\n",
    "            # Define the custom ranking for each ordinal variable\n",
    "            cut_categories= ['Fair','Good','Very Good','Premium','Ideal']\n",
    "            color_categories= ['D','E','F','G','H','I','J']\n",
    "            clarity_categories= ['I1','SI2','SI1','VS2','VS1','VVS2','VVS1','IF']\n",
    "\n",
    "            logging.info(\"Pipeline initiated\")\n",
    "\n",
    "            #Numerical Pipeline\n",
    "            num_pipeline= Pipeline(\n",
    "                steps=   [\n",
    "                ('imputer',SimpleImputer(strategy='median')),\n",
    "                ('scaler',StandardScaler())\n",
    "            ])\n",
    "\n",
    "            #Categorical Pipeline\n",
    "            cat_pipeline= Pipeline(\n",
    "                steps=[\n",
    "                ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "                ('ordinalencoder',OrdinalEncoder(categories=[cut_categories,color_categories,clarity_categories])),\n",
    "                ('scaler',StandardScaler())\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            preprocessor= ColumnTransformer([\n",
    "                ('num_pipeline',num_pipeline,numerical_cols),\n",
    "                ('cat_pipeline',cat_pipeline,categorical_cols)\n",
    "            ])\n",
    "            return preprocessor\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info(\"error initiate in data transformation\")\n",
    "            raise customexception(e,sys)\n",
    "        \n",
    "    def initialize_data_transformation(self, train_path, test_path):\n",
    "        try:\n",
    "            train_df= pd.read_csv(train_path)\n",
    "            test_df= pd.read_csv(test_path)\n",
    "\n",
    "            logging.info(\"read train and test data complete\")\n",
    "            logging.info(f'Train data head : \\n{train_df.head().to_string()}')\n",
    "            logging.info(f'Test data head : \\n{test_df.head().to_string()}')\n",
    "            \n",
    "            preprocessing_obj= self.get_data_transformation()\n",
    "            \n",
    "            target_column_name= 'price'\n",
    "            drop_columns= [target_column_name,'id']\n",
    "\n",
    "            input_feature_train_df= train_df.drop(columns=drop_columns, axis= 1)\n",
    "            target_feature_train_df= train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df= test_df.drop(columns=drop_columns, axis= 1)\n",
    "            target_feature_test_df= test_df[target_column_name]\n",
    "\n",
    "            input_feature_train_arr= preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr= preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            \n",
    "            logging.info(\"Applying preprocessing on train and test datasets\")\n",
    "\n",
    "            save_object(\n",
    "                file_path= self.data_transformation_config.preprocessor_obj_file_path,\n",
    "                obj= preprocessing_obj\n",
    "            )\n",
    "            \n",
    "            return(\n",
    "                input_feature_train_arr,\n",
    "                input_feature_test_arr\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.info(\"Exception initiate in data ingestion\")\n",
    "            raise customexception(e,sys)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self):\n",
    "        self.data_transformation_config= DataTransformationConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_transformation(self):\n",
    "        try:\n",
    "            \n",
    "            logging.info(\"Data transformation initiated\")\n",
    "\n",
    "            # Define which column should be ordinal encoded and which should be scaled\n",
    "            categorical_cols= ['cut','clarity','color']\n",
    "            numerical_cols= ['carat','depth','table','x','y','z']\n",
    "\n",
    "            # Define the custom ranking for each ordinal variable\n",
    "            cut_categories= ['Fair','Good','Very Good','Premium','Ideal']\n",
    "            color_categories= ['D','E','F','G','H','I','J']\n",
    "            clarity_categories= ['I1','SI2','SI1','VS2','VS1','VVS2','VVS1','IF']\n",
    "\n",
    "            logging.info(\"Pipeline initiated\")\n",
    "\n",
    "            #Numerical Pipeline\n",
    "            num_pipeline= Pipeline(\n",
    "                steps=   [\n",
    "                ('imputer',SimpleImputer(strategy='median')),\n",
    "                ('scaler',StandardScaler())\n",
    "            ])\n",
    "\n",
    "            #Categorical Pipeline\n",
    "            cat_pipeline= Pipeline(\n",
    "                steps=[\n",
    "                ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "                ('ordinalencoder',OrdinalEncoder(categories=[cut_categories,color_categories,clarity_categories])),\n",
    "                ('scaler',StandardScaler())\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            preprocessor= ColumnTransformer([\n",
    "                ('num_pipeline',num_pipeline,numerical_cols),\n",
    "                ('cat_pipeline',cat_pipeline,categorical_cols)\n",
    "            ])\n",
    "            return preprocessor\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info(\"error initiate in data transformation\")\n",
    "            raise customexception(e,sys)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data_transformation(self, train_path, test_path):\n",
    "        try:\n",
    "            train_df= pd.read_csv(train_path)\n",
    "            test_df= pd.read_csv(test_path)\n",
    "\n",
    "            logging.info(\"read train and test data complete\")\n",
    "            logging.info(f'Train data head : \\n{train_df.head().to_string()}')\n",
    "            logging.info(f'Test data head : \\n{test_df.head().to_string()}')\n",
    "            \n",
    "            preprocessing_obj= self.get_data_transformation()\n",
    "            \n",
    "            target_column_name= 'price'\n",
    "            drop_columns= [target_column_name,'id']\n",
    "\n",
    "            input_feature_train_df= train_df.drop(columns=drop_columns, axis= 1)\n",
    "            target_feature_train_df= train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df= test_df.drop(columns=drop_columns, axis= 1)\n",
    "            target_feature_test_df= test_df[target_column_name]\n",
    "\n",
    "            input_feature_train_arr= preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr= preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            \n",
    "            logging.info(\"Applying preprocessing on train and test datasets\")\n",
    "\n",
    "            save_object(\n",
    "                file_path= self.data_transformation_config.preprocessor_obj_file_path,\n",
    "                obj= preprocessing_obj\n",
    "            )\n",
    "            \n",
    "            return(\n",
    "                input_feature_train_arr,\n",
    "                input_feature_test_arr\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.info(\"Exception initiate in data ingestion\")\n",
    "            raise customexception(e,sys)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
